{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hafizbudi/active-learning/blob/main/Digits_RS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN4dzlYaDzFR"
   },
   "source": [
    "## **Digits with random sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0RrpqbbD3dq"
   },
   "source": [
    "## **Connect to google drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuvgfCpIDvt2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJwlOMRiEH1p"
   },
   "outputs": [],
   "source": [
    "%cd gdrive/My Drive/Project/active_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJgwBxQl0TFp"
   },
   "outputs": [],
   "source": [
    "pip install modal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ2NcwtkKeda"
   },
   "source": [
    "## **Load library and digits data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "FsK42GhpKZ4t"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import dataclasses\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eO_DbX1dKz90"
   },
   "source": [
    "## **Load, Train and Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "D4ROQcRms35k"
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "# array to save number of instance and accuracy result\n",
    "instance_number = []\n",
    "accuracy_result = []\n",
    "\n",
    "# flatten into 1d array\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "Y = digits.target\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "QhXNpgllv-7I"
   },
   "outputs": [],
   "source": [
    "# data_points 100,...,900\n",
    "data_points=range(30,400,10)\n",
    "\n",
    "# train a classifier and predict\n",
    "def train_and_predict(n_instances, X_train, y_train, X_test):\n",
    "    clf = RandomForestClassifier()\n",
    "    \n",
    "    dataset_size = len(X_train)\n",
    "    potential_candidates = list(range(dataset_size))\n",
    "    train_indexes = np.array(random.sample(potential_candidates, n_instances))\n",
    "    #print(train_indexes)\n",
    "    clf.fit(X_train[train_indexes], y_train[train_indexes])\n",
    "    predicted = clf.predict(X_test)\n",
    "    return predicted\n",
    "\n",
    "def random_selection_learning(n_instances, X_train, y_train):\n",
    "    clf = RandomForestClassifier()\n",
    "    #clf = LogisticRegression()\n",
    "    X_selected, X_not_selected, y_selected, y_not_selected = \\\n",
    "        train_test_split(X_train, y_train, train_size=n_instances, shuffle=True)\n",
    "    clf.fit(X_selected, y_selected)\n",
    "    return clf, X_selected, X_not_selected, y_selected, y_not_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9d-RJVpwHCJ",
    "outputId": "388b87d5-16fd-4656-ab76-27c69a3cf84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.89s/it]\n",
      " 80%|████████  | 4/5 [00:16<00:04,  4.17s/it]"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X_real, y_real):\n",
    "    y_predictions = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_real,y_predictions)\n",
    "    #print(f\"{accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    n_samples: int\n",
    "    repeat: int\n",
    "    accuracy: float\n",
    "\n",
    "def random_sampling_policy(model, n_new_samples, X_remaining, y_remaining):\n",
    "    #print(\"n_new_samples \",n_new_samples)\n",
    "    X_new_selected, X_remaining, y_new_selected, y_remaining = \\\n",
    "               train_test_split(X_remaining, y_remaining,  train_size=n_new_samples, shuffle=True)\n",
    "    return X_new_selected, X_remaining, y_new_selected, y_remaining\n",
    "\n",
    "def uncertainty_sampling_policy(model, n_new_samples, X_remaining, y_remaining):\n",
    "    y_proba = model.predict_proba(X_remaining)\n",
    "    uncertainty = 1. - np.max(y_proba, axis=1)\n",
    "    #uncertainty = -scipy.stats.entropy(y_proba, axis=1)\n",
    "    #print(uncertainty)\n",
    "    ordered_positions = uncertainty.argsort()\n",
    "    selected = ordered_positions[-n_new_samples:]\n",
    "    #print(len(selected))\n",
    "    non_selected = ordered_positions[:-n_new_samples]\n",
    "    #print(len(non_selected))#print(non_selected)\n",
    "    return X_remaining[selected], X_remaining[non_selected], y_remaining[selected], y_remaining[non_selected]\n",
    "\n",
    "def learning_curve(data_points, repeats, selection_policy):\n",
    "    experiments = []\n",
    "    for i in tqdm(range(repeats)):\n",
    "        np.random.seed(123+i)\n",
    "        # First learn \n",
    "        n_samples = data_points[0]\n",
    "        #print(\"n_samples\",n_samples)\n",
    "        model, X_selected, X_remaining, y_selected, y_remaining = \\\n",
    "            random_selection_learning(n_samples, X_train, y_train)\n",
    "        acc = evaluate(model, X_test, y_test)\n",
    "        experiments.append(Experiment(n_samples=n_samples, repeat=i, accuracy=acc))\n",
    "        for n_samples in data_points[1:]:\n",
    "            # Select the additional examples\n",
    "            n_new_samples = n_samples - len(X_selected)\n",
    "            #print(n_new_samples)\n",
    "            X_new_selected, X_remaining, y_new_selected, y_remaining = \\\n",
    "                selection_policy(model, n_new_samples, X_remaining, y_remaining)\n",
    "            \n",
    "            X_selected = np.vstack((X_selected, X_new_selected))\n",
    "            y_selected = np.hstack((y_selected, y_new_selected))\n",
    "            #print(X_selected.shape, y_selected.shape)\n",
    "            model.fit(X_selected, y_selected)\n",
    "            acc = evaluate(model, X_test, y_test)\n",
    "            experiments.append(Experiment(n_samples=n_samples, repeat=i, accuracy=acc))\n",
    "            \n",
    "    #print(\"mean n 100\", mean_n100)\n",
    "    #print(mean_n)\n",
    "    return experiments\n",
    "\n",
    "experiments_uncertainty = learning_curve(data_points, 5, uncertainty_sampling_policy)\n",
    "experiments_random = learning_curve(data_points, 5, random_sampling_policy)\n",
    "print(experiments)\n",
    "#print(\"Non-100 array\",mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataclasses.asdict(experiments[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([dataclasses.asdict(e) for e in experiments])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(df, name):\n",
    "    # Compute percentiles\n",
    "    p10 = df.groupby('n_samples').quantile(.10)['accuracy']\n",
    "    p50 = df.groupby('n_samples').median()['accuracy']\n",
    "    p90 = df.groupby('n_samples').quantile(.90)['accuracy']\n",
    "    training_sizes= p50.index.to_numpy()\n",
    "\n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.title('Learning curve for classifier '+name)\n",
    "        plt.plot(training_sizes, p50, label=name, marker='o')\n",
    "\n",
    "        # show standard deviation\n",
    "        plt.fill_between(training_sizes, p10, p90,alpha=0.1)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel(\"N sample\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random = pd.DataFrame([dataclasses.asdict(e) for e in experiments_random])\n",
    "df_us = pd.DataFrame([dataclasses.asdict(e) for e in experiments_uncertainty])\n",
    "plot_learning_curve(df_random, \"Random\")\n",
    "plot_learning_curve(df_us, \"Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNBe48WJ1dcQR+gyddsBKAG",
   "collapsed_sections": [
    "7wSC51HM5mkl",
    "ZX_iezA55cac",
    "KaDX73S75jtz",
    "QQU1DFUJao-i"
   ],
   "include_colab_link": true,
   "name": "Digits_RS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
